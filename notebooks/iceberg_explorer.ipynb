{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Apache Iceberg on Cloudflare R2\n",
    "\n",
    "This notebook demonstrates querying federal regulations data through the **R2 Data Catalog** (Apache Iceberg REST catalog).\n",
    "\n",
    "**What's different from raw Parquet?**\n",
    "- Tables are managed — schema evolution, ACID transactions, time travel\n",
    "- Multi-engine access — DuckDB, PyIceberg, Spark, Snowflake all see the same catalog\n",
    "- Incremental updates — append/update rows without rewriting entire files\n",
    "\n",
    "Data source: [regulations.gov](https://www.regulations.gov/) via [Mirrulations](https://github.com/MoravianUniversity/mirrulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# !pip install duckdb pandas python-dotenv pyiceberg[pyarrow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect via DuckDB\n",
    "\n",
    "DuckDB 1.4+ can attach directly to an Iceberg REST catalog. Once attached, tables are queryable with standard SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Iceberg catalog config\n",
    "CATALOG_URI = \"https://catalog.cloudflarestorage.com/a18589c7a7a0fc4febecadfc9c71b105/spicy-regs\"\n",
    "WAREHOUSE = \"a18589c7a7a0fc4febecadfc9c71b105_spicy-regs\"\n",
    "TOKEN = os.getenv(\"R2_API_TOKEN\")\n",
    "\n",
    "# Initialize DuckDB with Iceberg support\n",
    "conn = duckdb.connect()\n",
    "conn.execute(\"INSTALL iceberg; LOAD iceberg;\")\n",
    "conn.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Authenticate\n",
    "conn.execute(f\"\"\"\n",
    "    CREATE SECRET r2_secret (\n",
    "        TYPE ICEBERG,\n",
    "        TOKEN '{TOKEN}'\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Attach the catalog\n",
    "conn.execute(f\"\"\"\n",
    "    ATTACH '{WAREHOUSE}' AS spicy_regs (\n",
    "        TYPE ICEBERG,\n",
    "        ENDPOINT '{CATALOG_URI}'\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Connected to Iceberg catalog\")\n",
    "print(f\"DuckDB {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discover the Catalog\n",
    "\n",
    "Browse schemas (namespaces) and tables — just like a traditional database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tables in the catalog\n",
    "conn.execute(\"SHOW ALL TABLES\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the active schema for shorter queries\n",
    "conn.execute(\"USE spicy_regs.regulations\")\n",
    "print(\"✓ Active schema: spicy_regs.regulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the schema of each table\n",
    "for table in [\"dockets\", \"documents\", \"comments\"]:\n",
    "    print(f\"\\n── {table} ──\")\n",
    "    display(conn.execute(f\"DESCRIBE {table}\").fetchdf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Overview\n",
    "\n",
    "Get row counts and basic stats — same queries as the Parquet notebook, but now reading from managed Iceberg tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row counts for all tables\n",
    "for table in [\"dockets\", \"documents\", \"comments\"]:\n",
    "    count = conn.execute(f\"SELECT COUNT(*) FROM {table}\").fetchone()[0]\n",
    "    agencies = conn.execute(f\"SELECT COUNT(DISTINCT agency_code) FROM {table}\").fetchone()[0]\n",
    "    print(f\"{table}: {count:,} rows, {agencies} agencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Examples\n",
    "\n",
    "### Top Agencies by Docket Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "    SELECT agency_code, COUNT(*) as docket_count\n",
    "    FROM dockets\n",
    "    GROUP BY agency_code\n",
    "    ORDER BY docket_count DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recent EPA Dockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "    SELECT docket_id, title, docket_type, modify_date\n",
    "    FROM dockets\n",
    "    WHERE agency_code = 'EPA'\n",
    "    ORDER BY modify_date DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents with Open Comment Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "    SELECT document_id, agency_code, title, \n",
    "           comment_start_date, comment_end_date\n",
    "    FROM documents\n",
    "    WHERE comment_end_date IS NOT NULL\n",
    "      AND TRY_CAST(comment_end_date AS DATE) > CURRENT_DATE\n",
    "    ORDER BY comment_end_date ASC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Commented Dockets (Cross-Table Join)\n",
    "\n",
    "This is where Iceberg shines — joins across managed tables work like a traditional database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        d.docket_id,\n",
    "        d.agency_code,\n",
    "        d.title,\n",
    "        COUNT(c.comment_id) as comment_count\n",
    "    FROM dockets d\n",
    "    LEFT JOIN comments c ON d.docket_id = c.docket_id\n",
    "    WHERE d.agency_code = 'EPA'\n",
    "    GROUP BY d.docket_id, d.agency_code, d.title\n",
    "    ORDER BY comment_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment Volume by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(YEAR FROM TRY_CAST(posted_date AS DATE))::INT as year,\n",
    "        EXTRACT(MONTH FROM TRY_CAST(posted_date AS DATE))::INT as month,\n",
    "        COUNT(*) as comment_count\n",
    "    FROM comments\n",
    "    WHERE posted_date IS NOT NULL \n",
    "      AND TRY_CAST(posted_date AS DATE) IS NOT NULL\n",
    "      AND TRY_CAST(posted_date AS DATE) >= DATE '2024-01-01'\n",
    "    GROUP BY 1, 2\n",
    "    ORDER BY 1, 2\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare: Iceberg vs Raw Parquet\n",
    "\n",
    "The same queries work against both. The key difference is how you reference the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "R2_PUBLIC_URL = \"https://pub-5fc11ad134984edf8d9af452dd1849d6.r2.dev\"\n",
    "\n",
    "query = \"SELECT agency_code, COUNT(*) as cnt FROM {source} GROUP BY 1 ORDER BY 2 DESC LIMIT 5\"\n",
    "\n",
    "# Iceberg table\n",
    "t0 = time.time()\n",
    "iceberg_result = conn.execute(query.format(source=\"dockets\")).fetchdf()\n",
    "iceberg_time = time.time() - t0\n",
    "\n",
    "# Raw Parquet\n",
    "t0 = time.time()\n",
    "parquet_result = conn.execute(\n",
    "    query.format(source=f\"read_parquet('{R2_PUBLIC_URL}/dockets.parquet')\")\n",
    ").fetchdf()\n",
    "parquet_time = time.time() - t0\n",
    "\n",
    "print(f\"Iceberg: {iceberg_time:.2f}s\")\n",
    "print(f\"Parquet:  {parquet_time:.2f}s\")\n",
    "print(f\"\\nResults match: {iceberg_result.equals(parquet_result)}\")\n",
    "display(iceberg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PyIceberg Access\n",
    "\n",
    "PyIceberg provides a Python-native way to interact with the catalog — useful for schema inspection, metadata access, and programmatic table management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog.rest import RestCatalog\n",
    "\n",
    "catalog = RestCatalog(\n",
    "    name=\"spicy_regs\",\n",
    "    warehouse=WAREHOUSE,\n",
    "    uri=CATALOG_URI,\n",
    "    token=TOKEN,\n",
    ")\n",
    "\n",
    "# List namespaces and tables\n",
    "print(\"Namespaces:\", catalog.list_namespaces())\n",
    "print(\"\\nTables:\")\n",
    "for table in catalog.list_tables(\"regulations\"):\n",
    "    print(f\"  {'.'.join(table)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect table metadata\n",
    "table = catalog.load_table((\"regulations\", \"dockets\"))\n",
    "\n",
    "print(f\"Table: {table.name()}\")\n",
    "print(f\"Location: {table.location()}\")\n",
    "print(f\"Snapshots: {len(table.metadata.snapshots)}\")\n",
    "print(f\"\\nSchema:\")\n",
    "for field in table.schema().fields:\n",
    "    print(f\"  {field.name}: {field.field_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data via PyIceberg → Arrow → Pandas\n",
    "arrow_table = table.scan(\n",
    "    selected_fields=(\"docket_id\", \"agency_code\", \"title\"),\n",
    "    limit=5\n",
    ").to_arrow()\n",
    "\n",
    "arrow_table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter with row-level predicates (pushed down to Iceberg)\n",
    "from pyiceberg.expressions import EqualTo\n",
    "\n",
    "epa_dockets = catalog.load_table((\"regulations\", \"dockets\")).scan(\n",
    "    row_filter=EqualTo(\"agency_code\", \"EPA\"),\n",
    "    selected_fields=(\"docket_id\", \"title\", \"docket_type\"),\n",
    "    limit=10\n",
    ").to_arrow()\n",
    "\n",
    "print(f\"EPA dockets (filtered at scan level): {len(epa_dockets)} rows\")\n",
    "epa_dockets.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Snapshot History (Time Travel)\n",
    "\n",
    "Every write to an Iceberg table creates a snapshot. You can inspect the history and (in the future) query historical versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for tbl_name in [\"dockets\", \"documents\", \"comments\"]:\n",
    "    tbl = catalog.load_table((\"regulations\", tbl_name))\n",
    "    print(f\"\\n── {tbl_name} ──\")\n",
    "    print(f\"  Snapshots: {len(tbl.metadata.snapshots)}\")\n",
    "    for snap in tbl.metadata.snapshots:\n",
    "        ts = datetime.fromtimestamp(snap.timestamp_ms / 1000)\n",
    "        summary = snap.summary or {}\n",
    "        rows = summary.get(\"total-records\", \"?\")\n",
    "        files = summary.get(\"total-data-files\", \"?\")\n",
    "        print(f\"  Snapshot {snap.snapshot_id}: {ts} | {rows} records, {files} data files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Best For |\n",
    "|--------|----------|\n",
    "| **DuckDB SQL** | Ad-hoc queries, joins, aggregations — most natural for analytics |\n",
    "| **PyIceberg** | Schema inspection, metadata access, programmatic table management |\n",
    "| **Raw Parquet** | Quick reads when you don't need catalog features |\n",
    "\n",
    "All three access the same underlying data on Cloudflare R2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
