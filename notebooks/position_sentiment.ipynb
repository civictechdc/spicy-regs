{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position & Sentiment Analysis\n",
    "\n",
    "**Problem**: How can we extract nuanced positions and sentiments from comments beyond simple for/against categorizations?\n",
    "\n",
    "**Stakeholder Quotes:**\n",
    "- \"Sophisticated position analysis… can we use LLMs?\"\n",
    "- \"How many credible commenters made similar points?\"\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Rule-based sentiment indicators\n",
    "- Keyword-based position detection\n",
    "- Clustering comments by stance\n",
    "- LLM integration for nuanced analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ready\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "R2_BASE_URL = \"https://pub-5fc11ad134984edf8d9af452dd1849d6.r2.dev\"\n",
    "\n",
    "conn = duckdb.connect()\n",
    "conn.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "print(\"✓ Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: Standards of Performance for New, Reconstructed, and Modified  Sources and Emiss...\n"
     ]
    }
   ],
   "source": [
    "# Select a docket to analyze\n",
    "docket_id = \"EPA-HQ-OAR-2021-0317\"  # Change to your target docket\n",
    "\n",
    "# Get docket info\n",
    "docket_info = conn.execute(f\"\"\"\n",
    "    SELECT docket_id, agency_code, title\n",
    "    FROM read_parquet('{R2_BASE_URL}/dockets.parquet')\n",
    "    WHERE docket_id = '{docket_id}'\n",
    "\"\"\").fetchdf()\n",
    "print(f\"Analyzing: {docket_info['title'].iloc[0][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Keyword-Based Position Detection\n",
    "\n",
    "Identify support/opposition signals through specific phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define position indicators\n",
    "support_keywords = [\n",
    "    'support', 'favor', 'agree', 'endorse', 'approve', 'applaud',\n",
    "    'commend', 'encourage', 'welcome', 'urge you to finalize',\n",
    "    'strongly support', 'fully support'\n",
    "]\n",
    "\n",
    "oppose_keywords = [\n",
    "    'oppose', 'against', 'reject', 'disagree', 'concerned',\n",
    "    'harmful', 'damaging', 'negative', 'withdraw', 'rescind',\n",
    "    'strongly oppose', 'urge you to withdraw'\n",
    "]\n",
    "\n",
    "# Build SQL conditions\n",
    "support_cond = \" OR \".join([f\"LOWER(comment) LIKE '%{kw}%'\" for kw in support_keywords])\n",
    "oppose_cond = \" OR \".join([f\"LOWER(comment) LIKE '%{kw}%'\" for kw in oppose_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position breakdown:\n",
      "  neutral/unclear: 3,161 (86.9%)\n",
      "  support: 202 (5.6%)\n",
      "  oppose: 147 (4.0%)\n",
      "  mixed: 127 (3.5%)\n"
     ]
    }
   ],
   "source": [
    "# Classify comments by position\n",
    "positions = conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN ({support_cond}) AND NOT ({oppose_cond}) THEN 'support'\n",
    "            WHEN ({oppose_cond}) AND NOT ({support_cond}) THEN 'oppose'\n",
    "            WHEN ({support_cond}) AND ({oppose_cond}) THEN 'mixed'\n",
    "            ELSE 'neutral/unclear'\n",
    "        END as position,\n",
    "        COUNT(*) as count\n",
    "    FROM read_parquet('{R2_BASE_URL}/comments.parquet')\n",
    "    WHERE docket_id = '{docket_id}'\n",
    "      AND comment IS NOT NULL\n",
    "    GROUP BY position\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Position breakdown:\")\n",
    "total = positions['count'].sum()\n",
    "for _, row in positions.iterrows():\n",
    "    pct = 100 * row['count'] / total\n",
    "    print(f\"  {row['position']}: {row['count']:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Key Arguments\n",
    "\n",
    "Find the most common phrases and arguments in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common phrases in comments:\n",
      "  oil and: 850\n",
      "  and gas: 766\n",
      "  methane pollution: 377\n",
      "  the epa: 364\n",
      "  the oil: 233\n",
      "  thank you: 231\n",
      "  methane emissions: 226\n",
      "  climate change: 224\n",
      "  natural gas: 204\n",
      "  pollution from: 193\n",
      "  from the: 193\n",
      "  gas industry: 186\n",
      "  the proposed: 174\n",
      "  gas operations: 172\n",
      "  you for: 163\n",
      "  public health: 126\n",
      "  epa rsquo: 121\n",
      "  the climate: 116\n",
      "  flaring oil: 112\n",
      "  routine flaring: 110\n",
      "  from oil: 109\n",
      "  emissions from: 102\n",
      "  new mexico: 102\n",
      "  greenhouse gas: 100\n",
      "  and new: 95\n"
     ]
    }
   ],
   "source": [
    "# Sample comments for text analysis\n",
    "sample = conn.execute(f\"\"\"\n",
    "    SELECT comment\n",
    "    FROM read_parquet('{R2_BASE_URL}/comments.parquet')\n",
    "    WHERE docket_id = '{docket_id}'\n",
    "      AND comment IS NOT NULL\n",
    "      AND LENGTH(comment) > 100\n",
    "    LIMIT 500\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Extract common phrases (bigrams)\n",
    "all_bigrams = []\n",
    "for text in sample['comment'].dropna():\n",
    "    words = re.findall(r'\\b[a-z]{3,}\\b', text.lower())\n",
    "    bigrams = [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "    all_bigrams.extend(bigrams)\n",
    "\n",
    "# Filter out common/boring bigrams\n",
    "stopbigrams = {'the the', 'of the', 'in the', 'to the', 'and the', 'for the', 'this is', 'that the'}\n",
    "meaningful = [b for b in all_bigrams if b not in stopbigrams]\n",
    "\n",
    "print(\"Common phrases in comments:\")\n",
    "for phrase, count in Counter(meaningful).most_common(25):\n",
    "    print(f\"  {phrase}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Intensity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment intensity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>3220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strong</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intensity  count\n",
       "0  moderate   3220\n",
       "1    strong    417"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intensity indicators\n",
    "strong_indicators = ['strongly', 'absolutely', 'extremely', 'deeply', 'urgently', \n",
    "                     'critical', 'essential', 'must', 'demand', 'insist']\n",
    "\n",
    "strong_cond = \" OR \".join([f\"LOWER(comment) LIKE '%{kw}%'\" for kw in strong_indicators])\n",
    "\n",
    "intensity = conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        CASE WHEN ({strong_cond}) THEN 'strong' ELSE 'moderate' END as intensity,\n",
    "        COUNT(*) as count\n",
    "    FROM read_parquet('{R2_BASE_URL}/comments.parquet')\n",
    "    WHERE docket_id = '{docket_id}'\n",
    "      AND comment IS NOT NULL\n",
    "    GROUP BY intensity\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Sentiment intensity:\")\n",
    "intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Comments by Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample SUPPORTING comments:\n",
      "============================================================\n",
      "\n",
      "[EPA-HQ-OAR-2021-0317-0208] Anonymous public comment\n",
      "The EPA has long been an enforcement agency of the radical left. Time and time again their &quot;recommendations&quot; have been nothing more than the furthering of a radical left-wing agenda on climate change policies that do nothing but cripple America, kill jobs, and make us dependent on foreign ...\n",
      "\n",
      "[EPA-HQ-OAR-2021-0317-0220] Comment submitted by C. Runyon\n",
      " I agree that there needs to be some laws and rules to control emissions. However, the restrictions should not put companies in financial jeopardy.  There are <br/>small producers in the Oil &amp; Gas Industry that do not have large amounts of cash.  They are barely surviving as it is.  With these r...\n",
      "\n",
      "[EPA-HQ-OAR-2021-0317-0240] Anonymous public comment\n",
      "EPA Administrator Michael Regan,<br/><br/>I am writing in support of the EPA&rsquo;s proposed methane standard and to ask that the EPA take stronger action to reduce methane pollution. <br/><br/>Living in the energy sacrifice zone of southwestern Pennsylvania, I have witnessed firsthand the terrible...\n"
     ]
    }
   ],
   "source": [
    "# Sample supporting comments\n",
    "support_sample = conn.execute(f\"\"\"\n",
    "    SELECT comment_id, title, LEFT(comment, 400) as excerpt\n",
    "    FROM read_parquet('{R2_BASE_URL}/comments.parquet')\n",
    "    WHERE docket_id = '{docket_id}'\n",
    "      AND comment IS NOT NULL\n",
    "      AND ({support_cond})\n",
    "      AND NOT ({oppose_cond})\n",
    "      AND LENGTH(comment) > 200\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Sample SUPPORTING comments:\")\n",
    "print(\"=\" * 60)\n",
    "for _, row in support_sample.iterrows():\n",
    "    print(f\"\\n[{row['comment_id']}] {row['title']}\")\n",
    "    print(row['excerpt'][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample OPPOSING comments:\n",
      "============================================================\n",
      "\n",
      "[EPA-HQ-OAR-2021-0317-0206] Comment submitted by David  Roche\n",
      "With energy costs rising almost daily this new regulation needs to be looked at thoroughly. We can control harmful emissions better with innovation instead of more regulation. At this point in time I am against this proposed nothing in regulation ruling....\n",
      "\n",
      "[EPA-HQ-OAR-2021-0317-0202] Comment submitted by Amy Sindorf\n",
      "Hello,<br/><br/>I am new to this process but as I see the world changing and the risk of our own human extinction increasing everyday, I feel the need to start getting more involved. I&rsquo;m not a scientist or an expert in this field, but I&rsquo;m a citizen who as watched the world<br/>Change as ...\n",
      "\n",
      "[EPA-HQ-OAR-2021-0317-0213] Comment submitted by Robert Pitkin\n",
      "I am opposed to this further rule on methane in the oil industry for the following reasons.  It will reduce production of oil by increasing cost of production, raising cost of living for all Americans, slowing our economy.  It does nothing to reduce pollution from methane by other countries,  The am...\n"
     ]
    }
   ],
   "source": [
    "# Sample opposing comments\n",
    "oppose_sample = conn.execute(f\"\"\"\n",
    "    SELECT comment_id, title, LEFT(comment, 400) as excerpt\n",
    "    FROM read_parquet('{R2_BASE_URL}/comments.parquet')\n",
    "    WHERE docket_id = '{docket_id}'\n",
    "      AND comment IS NOT NULL\n",
    "      AND ({oppose_cond})\n",
    "      AND NOT ({support_cond})\n",
    "      AND LENGTH(comment) > 200\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Sample OPPOSING comments:\")\n",
    "print(\"=\" * 60)\n",
    "for _, row in oppose_sample.iterrows():\n",
    "    print(f\"\\n[{row['comment_id']}] {row['title']}\")\n",
    "    print(row['excerpt'][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM-Based Analysis (Optional)\n",
    "\n",
    "For more nuanced analysis, use an LLM to classify positions and extract arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM prompt template for position analysis:\n",
      "\n",
      "Analyze this public comment on a federal regulation. Extract:\n",
      "1. Overall position (support/oppose/neutral/mixed)\n",
      "2. Key arguments (bullet points)\n",
      "3. Specific concerns or suggestions\n",
      "4. Emotional tone (professional, passionate, hostile, constructive)\n",
      "\n",
      "Comment:\n",
      "{comment_text}\n",
      "\n",
      "Analysis:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example LLM prompt for position analysis\n",
    "# Uncomment and add your API key to use\n",
    "\n",
    "llm_prompt = \"\"\"\n",
    "Analyze this public comment on a federal regulation. Extract:\n",
    "1. Overall position (support/oppose/neutral/mixed)\n",
    "2. Key arguments (bullet points)\n",
    "3. Specific concerns or suggestions\n",
    "4. Emotional tone (professional, passionate, hostile, constructive)\n",
    "\n",
    "Comment:\n",
    "{comment_text}\n",
    "\n",
    "Analysis:\n",
    "\"\"\"\n",
    "\n",
    "print(\"LLM prompt template for position analysis:\")\n",
    "print(llm_prompt)\n",
    "\n",
    "# Example with OpenAI (uncomment to use)\n",
    "# import openai\n",
    "# openai.api_key = \"your-key\"\n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": llm_prompt.format(comment_text=comment)}]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
